from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import statsmodels.api as sm
import numpy as np
import pandas as pd



# Initialize SVM Classifier with specified parameters
dt = DecisionTreeRegressor(
    criterion='squared_error',
    max_features=None,
    max_depth=5,
    min_samples_split=2,
    min_samples_leaf=1,
    random_state=20,
)

# Train the model
dt.fit(X_train, y_train)

# Predict on the test set
y_pred = dt.predict(X_test)

# Evaluate the model
# Compute metrics
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

# Calculate Adjusted R²
n = len(y_test)
p = X_test.shape[1]
k = X_test.shape[1] + 1

adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)

# Calculate MAPE (Mean Absolute Percentage Error)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100


# Display all metrics
print('----------------------------')
print('jupyter Results :')
calculate_aic_bic(n,mse, k)
print(f"Adjusted R²: {adjusted_r2}")
print(f"MAE: {mae}")
print(f"MAPE: {mape}")
print(f"MSE: {mse}")
print(f"R²: {r2}")
print(f"RMSE: {rmse}")

print('----------------------------')
print('Comparision with Rubi : ')
print('''DT
AIC49084.9709
Adjusted R Square0.6991
BIC49187.0792
MAE1888.4166
MAPE25.5318
MSE12614072.873
R Square0.7008
RMSE3551.6296''')
print('----------------------------')
